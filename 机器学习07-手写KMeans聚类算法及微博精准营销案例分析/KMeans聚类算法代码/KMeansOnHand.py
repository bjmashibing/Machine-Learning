# encoding:utf-8import numpy as npfrom sklearn.cluster import KMeansimport matplotlib.pyplot as pltplt.figure(figsize=(12, 12))def loadDataSet(fileName):    '''         list集合    '''    dataMat = []    fr = open(fileName)    for line in fr.readlines():        curLine = line.strip().split('\t')        fltLine = list(map(float, curLine))        dataMat.append(fltLine)    return dataMat# 计算两个样本之间的距离（欧式距离）def distEclud(vecA, vecB):    return np.sqrt(np.sum(np.power(vecA - vecB, 2)))'''    随机选取K个中心点的坐标'''def randCent(dataSet, k):    # n=2    n = np.shape(dataSet)[1]    '''        centroids是一个3*2的矩阵，用于存储k个中心点的坐标    '''    centroids = np.mat(np.zeros((k, n)))    for j in range(n):        minJ = np.min(dataSet[:, j])        rangeJ = np.max(dataSet[:, j]) - minJ        centroids[:, j] = np.mat(minJ + rangeJ * np.random.rand(k, 1))    return centroidsdef kMeans(dataSet, k, distMeas=distEclud, createCent=randCent):    # 获取矩阵的形状    80*2    m = np.shape(dataSet)[0]    # 创建一个80*2零矩阵    clusterAssment = np.mat(np.zeros((m, 2)))    #     createCent找到K个随机中心点（虚拟的中心点）    centroids = createCent(dataSet, k)    # 控制迭代    clusterChanged = True    while clusterChanged:        clusterChanged = False        for i in range(m):            minDist = np.inf            minIndex = -1            # 遍历K个中心点            for j in range(k):                # 取的第二个中心点                x = centroids[j, :]                # 第一个样本与第二个中心点的距离 欧式距离                distJI = distMeas(x, dataSet[i, :])                if distJI < minDist:                    minDist = distJI                    minIndex = j            if clusterAssment[i, 0] != minIndex: clusterChanged = True            clusterAssment[i, :] = minIndex, minDist            # 更新每一类的新的中心点坐标        for cent in range(k):            # nonzero返回符合条件的数据的索引值            ptsInClust = dataSet[np.nonzero(clusterAssment[:, 0].A == cent)[0]]            centroids[cent, :] = np.mean(ptsInClust, axis=0)    #         centroids最终聚类完的中心点坐标     clusterAssment记录每一条样本的分类以及与当前类的中心点的距离    return centroids, clusterAssmentif __name__ == '__main__':    dataMat = np.mat(loadDataSet('testSet.txt'))    k = 4    centroids, clusterAssment = kMeans(dataMat, k, distMeas=distEclud, createCent=randCent)    print(clusterAssment)    print(centroids)    # 将聚类的结果 使用散点图的形式展现出来    matplotlib    dataMat = np.array(dataMat)    # 存储是每一个样本的分类号  plt理解成就是一个画布    y_pred1 = np.array([int(i) for j in clusterAssment[:, 0].A for i in j])    plt.scatter(dataMat[:, 0], dataMat[:, 1], c=y_pred1)    plt.title("kmeans")    plt.show()